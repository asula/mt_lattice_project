# MERT optimized configuration
# decoder /home/marit/mosesdecoder/bin/moses
# BLEU 0.260323 on dev /home/marit/mt/europarl/dev.et
# We were before running iteration 7
# finished T dets  13 01:56:18 EET 2016
### MOSES CONFIG FILE ###
#########################

[beam-threshold]
0.05

# input factors
[input-factors]
0

# mapping steps
[mapping]
0 T 0

[distortion-limit]
6

[inputtype]
2

[verbose]
2

# feature functions
[feature]
UnknownWordPenalty
WordPenalty
PhrasePenalty
PhraseDictionaryMemory name=TranslationModel0 num-features=4 path=/home/marit/mt/europarl/exp2/model/phrase-table.gz input-factor=0 output-factor=0
LexicalReordering name=LexicalReordering0 num-features=6 type=wbe-msd-bidirectional-fe-allff input-factor=0 output-factor=0 path=/home/marit/mt/europarl/exp2/model/reordering-table.wbe-msd-bidirectional-fe.gz
Distortion
KENLM name=LM0 factor=0 path=/home/marit/mt/europarl/lang_models/lm-en75.arpa order=5
InputFeature num-features=1 num-input-features=1 real-word-count=0

# dense weights for feature functions
[weight]

LexicalReordering0= 0.0734237 0.056562 0.0324186 0.0644776 0.00658209 0.0966717
Distortion0= 0.036959
LM0= 0.0903932
WordPenalty0= -0.239165
PhrasePenalty0= 0.0975208
TranslationModel0= 0.0644535 0.0517107 0.0304218 0.0592406
UnknownWordPenalty0= 1
InputFeature0= 0.1
